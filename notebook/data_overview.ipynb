{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470242c6",
   "metadata": {},
   "source": [
    "## Dataset 1 & 2 Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4555b7aa-edc1-46e4-b5c7-ea913ddc908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hours_Studied  Attendance Parental_Involvement Access_to_Resources  \\\n",
      "0             23          84                  Low                High   \n",
      "1             19          64                  Low              Medium   \n",
      "2             24          98               Medium              Medium   \n",
      "3             29          89                  Low              Medium   \n",
      "4             19          92               Medium              Medium   \n",
      "\n",
      "  Extracurricular_Activities  Sleep_Hours  Previous_Scores Motivation_Level  \\\n",
      "0                         No            7               73              Low   \n",
      "1                         No            8               59              Low   \n",
      "2                        Yes            7               91           Medium   \n",
      "3                        Yes            8               98           Medium   \n",
      "4                        Yes            6               65           Medium   \n",
      "\n",
      "  Internet_Access  Tutoring_Sessions Family_Income Teacher_Quality  \\\n",
      "0             Yes                  0           Low          Medium   \n",
      "1             Yes                  2        Medium          Medium   \n",
      "2             Yes                  2        Medium          Medium   \n",
      "3             Yes                  1        Medium          Medium   \n",
      "4             Yes                  3        Medium            High   \n",
      "\n",
      "  School_Type Peer_Influence  Physical_Activity Learning_Disabilities  \\\n",
      "0      Public       Positive                  3                    No   \n",
      "1      Public       Negative                  4                    No   \n",
      "2      Public        Neutral                  4                    No   \n",
      "3      Public       Negative                  4                    No   \n",
      "4      Public        Neutral                  4                    No   \n",
      "\n",
      "  Parental_Education_Level Distance_from_Home  Gender  Exam_Score  \n",
      "0              High School               Near    Male          67  \n",
      "1                  College           Moderate  Female          61  \n",
      "2             Postgraduate               Near    Male          74  \n",
      "3              High School           Moderate    Male          71  \n",
      "4                  College               Near  Female          70  \n",
      "   Math_Score  Reading_Score  Writing_Score  Placement_Score  Club_Join_Date\n",
      "0          65             86             67               78            2021\n",
      "1          64             85             71               80            2019\n",
      "2          76             77             77               84            2021\n",
      "3          80             76             75               75            2021\n",
      "4          63             91             62               90            2019\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "# loading both dataset\n",
    "dataset1_url = \"https://raw.githubusercontent.com/hbedros/data622-assignment1/refs/heads/main/data/dataset-1.csv\"\n",
    "dataset2_url = \"https://raw.githubusercontent.com/hbedros/data622-assignment1/refs/heads/main/data/dataset-2.csv\"\n",
    "\n",
    "dataset1 = pd.read_csv(dataset1_url)\n",
    "dataset2 = pd.read_csv(dataset2_url)\n",
    "\n",
    "print(dataset1.head())\n",
    "print(dataset2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243e561",
   "metadata": {},
   "source": [
    "### Overview of the Datasets\n",
    "\n",
    "We have two datasets to work with:\n",
    "\n",
    "1. **Dataset 1 (dataset1.csv)**:\n",
    "   - This one has a bunch of columns about students, like how many hours they studied, their attendance, etc.\n",
    "   - It also includes some categories, like whether they had access to resources or if they were involved in extracurricular activities.\n",
    "   - Overall, it gives a good picture of their backgrounds and behaviors.\n",
    "\n",
    "2. **Dataset 2 (dataset2.csv)**:\n",
    "   - This dataset focuses on the actual scores: Math, Reading, Writing, and a Placement Score.\n",
    "   - It’s more about the outcomes of their studies.\n",
    "   - The Placement Score could be seen as an output. The results of the other exams could possibly indicate how they would perform on their placement exam.\n",
    "\n",
    "### Similarities and Differences\n",
    "\n",
    "**Similarities**:\n",
    "- Both datasets deal with students and their academic information.\n",
    "- They relate to how students perform in school, which is relevant for the analysis.\n",
    "\n",
    "**Differences**:\n",
    "- Dataset 1 has a lot more details about students' experiences and environments.\n",
    "- Dataset 2 is mainly about their scores, so it’s smaller and focused just on performance.\n",
    "\n",
    "### Analyzing the Data\n",
    "\n",
    "For the analysis, we aim to predict how well students will perform based on the information in Dataset 1. We will also determine if the math, reading, and writing scores from Dataset 2 indicate how a student will do on their placement exam.\n",
    "\n",
    "### Which Algorithms to Use\n",
    "\n",
    "To determine which algorithms will be best to use, we decided to consider multiple options and then choose two for comparison. The output variable is discrete because it is a numerical exam score without decimal points. The data contains many different input variables. Some of those variables will have a linear relationship with the exam score results, and some will not. Dataset 1 is relatively large compared to Dataset 2.\n",
    "\n",
    "Here are a couple of machine learning algorithms that could work well:\n",
    "\n",
    "1. **Random Forest Regression**:\n",
    "   - This is a complex algorithm that can handle a mix of numbers and categories. It is great if we think there might be non-linear relationships between the factors. The data is discrete since it does not use decimals, but the data can be treated as a continuous variable since the differences between values is meaningful. \n",
    "\n",
    "2. **KNN**:\n",
    "   - This algorithm is good for small datasets dealing with classification problems. It should perform well with Dataset 2. To use this with the large dataset, it makes sense to perform some dimensionality reduction. This can be done with Principal Component Analysis.\n",
    "\n",
    "3. **xGBoost**:\n",
    "   - This is a good starting point for analyzing data and creating models. This is good for complex, multi-dimensional data. It should work well with Dataset 1 and 2. We can use it after testing another model to see how they compare.\n",
    "\n",
    "Based on those options, we will use Random Forest Classification and xGBoost. KNN might produce better results for Dataset 2, but it will likely struggle with Dataset 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80d21d",
   "metadata": {},
   "source": [
    "## Applying Machine Learning Algorithms to Dataset 1 and Dataset 2\n",
    "\n",
    "In this section, we will apply Random Forest Regression and xGBoost algorithms to the datasets to create models. First, we will test Random Forest Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f24b49",
   "metadata": {},
   "source": [
    "### Random Forest Regression - Dataset 1\n",
    "\n",
    "We included several numeric variables in this random forest model, such as hours studied, attendance, sleep hours, previous scores, tutoring sessions, and physical activity. After splitting the data into training and testing sets, the model was trained and evaluated. The results showed some promise but left room for improvement. The **R-squared value** came out to be **0.54**, indicating that 54.1% of the variance in exam scores is explained by the model, leaving 45.9% unexplained. The **mean absolute error (MAE)** was **1.32**, which is a solid result considering the score scale is from 0 to 100. While these results are decent, there's definitely potential for better accuracy, so next, we’ll apply the **XGBoost** algorithm to see if we can achieve stronger performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7baf4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.558078874092011\n",
      "Mean Absolute Error: 1.32114406779661\n",
      "R-squared Score: 0.5410372811587938\n"
     ]
    }
   ],
   "source": [
    "X = dataset1[['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', \n",
    "              'Tutoring_Sessions', 'Physical_Activity', 'Teacher_Quality', \n",
    "              'Family_Income', 'Parental_Involvement']]  # adding the categorical stuff variables here\n",
    "Y = dataset1['Exam_Score']  # exam_score is what we're trying to predict\n",
    "\n",
    "categorical_columns = ['Teacher_Quality', 'Family_Income', 'Parental_Involvement']\n",
    "\n",
    "# one-hot encode the categorical variables and leave the numerical ones as they are\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', ['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', \n",
    "                                'Tutoring_Sessions', 'Physical_Activity']),  \n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# putting everything into a pipeline with the RandomForestRegressor\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # First, handle preprocessing\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=15))  # Then, the actual model\n",
    "])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')  # lower is better\n",
    "print(f'Mean Absolute Error: {mae}')  # lower is better\n",
    "print(f'R-squared Score: {r2}')  # higher is better here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117dfd6",
   "metadata": {},
   "source": [
    "### xGBoost - Gradient Boosting - Dataset 1\n",
    "\n",
    "Many numeric variables were included in this xGBoost model. These include hours studied, attendance, sleep hours, previous scores, tutoring sessions, and physical activity. The data was first split into train and test, the model was created with the train data, and then the model was analyzed with the test data. The results were not favorable. The **R-squared value** was quite low at **0.12**, meaning only **11.8%** of the variance in exam scores is explained by the model, leaving a significant **88.2%** unexplained. Additionally, the **mean absolute error (MAE)** was **2.73**, which is noticeably higher than the random forest model. On a scale from 0 to 100, an average error of **2.73** is less accurate, and this model performed worse overall compared to the random forest model. There's significant room for improvement in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "479435a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 14.531362795653902\n",
      "Mean Absolute Error: 2.7283759613591303\n",
      "R-squared Score: 0.11758611040394995\n"
     ]
    }
   ],
   "source": [
    "X = dataset1[['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity', \n",
    "              'Teacher_Quality', 'Family_Income', 'Parental_Involvement']]\n",
    "Y = dataset1['Exam_Score'] \n",
    "\n",
    "categorical_columns = ['Teacher_Quality', 'Family_Income', 'Parental_Involvement']\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', ['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', \n",
    "                                'Tutoring_Sessions', 'Physical_Activity']),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(n_estimators=45, learning_rate=0.07, random_state=23))\n",
    "])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared Score: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa678a",
   "metadata": {},
   "source": [
    "### Random Forest Regression - Dataset 2\n",
    "\n",
    "The math, reading, and writing exam scores were included in this random forest model. The data was first split into train and test, the model was created with the train data, and then the model was analyzed with the test data. It produced horrible results. The R-squared value was negative, indicating a performance worse than baseline. None of the variance can be explained by the model. Additionally, the mean absolute error was about 9.76. On a scale from 0 to 100, an average error of 9.76 indicates almost a 10% error rate. This data does not appear to be useful in predicting the results of a placement exam. Based on the EDA of this dataset, the results make sense because none of the variables were related. Their correlations were extremely low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60a689c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 141.6895601661111\n",
      "Mean Absolute Error: 9.787733333333332\n",
      "R-squared Score: -0.21580613084403177\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = dataset2[['Math_Score', 'Reading_Score', 'Writing_Score']]\n",
    "Y = dataset2['Placement_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=15)\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f'R-squared Score: {r2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233e6a2",
   "metadata": {},
   "source": [
    "### xGBoost - Gradient Boosting - Dataset 2\n",
    "\n",
    "The math, reading, and writing exam scores were included in this xGBoost model. The data was first split into train and test, the model was created with the train data, and then the model was analyzed with the test data. It produced horrible results, similar to the random forest model. The R-squared value was negative, indicating a performance worse than baseline. None of the variance can be explained by the model. Additionally, the mean absolute error was about 9.94. On a scale from 0 to 100, an average error of 9.94 indicates almost a 10% error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "420add96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 139.28098768582566\n",
      "Mean Absolute Error: 9.816615447998046\n",
      "R-squared Score: -0.19513871410083516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = dataset2[['Math_Score', 'Reading_Score', 'Writing_Score']]\n",
    "Y = dataset2['Placement_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(n_estimators=45, learning_rate=0.07, random_state=23)\n",
    "\n",
    "xgb_reg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared Score: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a8df7-8a0d-4bcf-87ab-686bbec35e08",
   "metadata": {},
   "source": [
    "## Results from the Datasets\n",
    "\n",
    "### Dataset 1:\n",
    "\n",
    "It appears that random forest regression and xGBoost models can be helpful in predicting exam scores from the provided information about students, but these models have much room for improvement. The R-squared value for the random forest regression was **0.54**, while for the xGBoost model it was significantly lower at **0.12**. However, the relatively low mean absolute error values, **1.32** for random forest and **2.73** for xGBoost, demonstrate some potential for use with future student data, though accuracy improvements are necessary.\n",
    "\n",
    "### Dataset 2:\n",
    "\n",
    "The negative R-squared values and high mean absolute errors demonstrate that no models will likely be helpful in predicting placement exam scores based on the other exam scores. The data should be used for other analysis, such as simple statistical analysis and exploratory data analysis. It should not be used for predictions since the scores are not related to one another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
