{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470242c6",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We're using the first dataset from our HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555b7aa-edc1-46e4-b5c7-ea913ddc908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hours_Studied  Attendance Parental_Involvement Access_to_Resources  \\\n",
      "0             23          84                  Low                High   \n",
      "1             19          64                  Low              Medium   \n",
      "2             24          98               Medium              Medium   \n",
      "3             29          89                  Low              Medium   \n",
      "4             19          92               Medium              Medium   \n",
      "\n",
      "  Extracurricular_Activities  Sleep_Hours  Previous_Scores Motivation_Level  \\\n",
      "0                         No            7               73              Low   \n",
      "1                         No            8               59              Low   \n",
      "2                        Yes            7               91           Medium   \n",
      "3                        Yes            8               98           Medium   \n",
      "4                        Yes            6               65           Medium   \n",
      "\n",
      "  Internet_Access  Tutoring_Sessions Family_Income Teacher_Quality  \\\n",
      "0             Yes                  0           Low          Medium   \n",
      "1             Yes                  2        Medium          Medium   \n",
      "2             Yes                  2        Medium          Medium   \n",
      "3             Yes                  1        Medium          Medium   \n",
      "4             Yes                  3        Medium            High   \n",
      "\n",
      "  School_Type Peer_Influence  Physical_Activity Learning_Disabilities  \\\n",
      "0      Public       Positive                  3                    No   \n",
      "1      Public       Negative                  4                    No   \n",
      "2      Public        Neutral                  4                    No   \n",
      "3      Public       Negative                  4                    No   \n",
      "4      Public        Neutral                  4                    No   \n",
      "\n",
      "  Parental_Education_Level Distance_from_Home  Gender  Exam_Score  \n",
      "0              High School               Near    Male          67  \n",
      "1                  College           Moderate  Female          61  \n",
      "2             Postgraduate               Near    Male          74  \n",
      "3              High School           Moderate    Male          71  \n",
      "4                  College               Near  Female          70  \n",
      "   Math_Score  Reading_Score  Writing_Score  Placement_Score  Club_Join_Date\n",
      "0          65             86             67               78            2021\n",
      "1          64             85             71               80            2019\n",
      "2          76             77             77               84            2021\n",
      "3          80             76             75               75            2021\n",
      "4          63             91             62               90            2019\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "# Loading the dataset\n",
    "dataset_url = \"https://raw.githubusercontent.com/hbedros/data622-assignment1/refs/heads/main/data/dataset-1.csv\"\n",
    "dataset = pd.read_csv(dataset_url)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243e561",
   "metadata": {},
   "source": [
    "### Overview of the Dataset\n",
    "\n",
    "From HW1, we only picked one dataset:\n",
    "\n",
    "- **Dataset (dataset.csv)**:\n",
    "  - This dataset includes various columns about students, such as study hours, attendance, and access to resources.\n",
    "  - It also contains categorical data, like extracurricular involvement.\n",
    "  - Overall, it provides a comprehensive picture of students' backgrounds and behaviors.\n",
    "\n",
    "### Analyzing the Data\n",
    "\n",
    "For the analysis, we aim to predict how well students will perform based on the information in this dataset. Our goal is to explore relationships between the available data points and student performance on their placement exam.\n",
    "\n",
    "### Which Algorithms to Use\n",
    "\n",
    "To identify the best algorithms, we will consider multiple options and then choose two for comparison. The output variable is discrete, as it represents a numerical exam score without decimal points. The dataset includes a mix of input variables, some of which may have a linear relationship with the exam score results, while others may not.\n",
    "\n",
    "Here are a couple of machine learning algorithms that could work well:\n",
    "\n",
    "1. **Random Forest Regression**:\n",
    "   - This algorithm can handle both numerical and categorical variables and is effective for non-linear relationships. While the data is discrete, it can be treated as a continuous variable because differences between values are meaningful.\n",
    "\n",
    "2. **xGBoost**:\n",
    "   - This is another strong choice for analyzing multi-dimensional data. It’s suitable for complex datasets and allows for effective model tuning and performance comparisons.\n",
    "\n",
    "Based on these options, we will use Random Forest Regression and xGBoost for the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80d21d",
   "metadata": {},
   "source": [
    "## Applying Machine Learning Algorithms to the Dataset\n",
    "\n",
    "In this section, we will apply Random Forest Regression and xGBoost algorithms to the dataset to create predictive models. First, we will test Random Forest Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f24b49",
   "metadata": {},
   "source": [
    "### Random Forest Regression\n",
    "\n",
    "We included several numeric variables in this random forest model, such as hours studied, attendance, sleep hours, previous scores, tutoring sessions, and physical activity. After splitting the data into training and testing sets, the model was trained and evaluated. The results showed some promise but left room for improvement. The **R-squared value** came out to be **0.54**, indicating that 54.1% of the variance in exam scores is explained by the model, leaving 45.9% unexplained. The **mean absolute error (MAE)** was **1.32**, which is a solid result considering the score scale is from 0 to 100. While these results are decent, there's definitely potential for better accuracy, so next, we’ll apply the **XGBoost** algorithm to see if we can achieve stronger performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7baf4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.558078874092011\n",
      "Mean Absolute Error: 1.32114406779661\n",
      "R-squared Score: 0.5410372811587938\n"
     ]
    }
   ],
   "source": [
    "# Select features and target variable\n",
    "X = dataset[['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', \n",
    "             'Tutoring_Sessions', 'Physical_Activity', 'Teacher_Quality', \n",
    "             'Family_Income', 'Parental_Involvement']]  # Adding categorical variables here\n",
    "Y = dataset['Exam_Score']  # Target variable: exam score to predict\n",
    "\n",
    "categorical_columns = ['Teacher_Quality', 'Family_Income', 'Parental_Involvement']\n",
    "\n",
    "# One-hot encode the categorical variables, leaving numerical ones as they are\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', ['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', \n",
    "                                'Tutoring_Sessions', 'Physical_Activity']),  \n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Define pipeline with preprocessing and RandomForestRegressor\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # First, handle preprocessing\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=15))  # Then, the actual model\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')  # Lower is better\n",
    "print(f'Mean Absolute Error: {mae}')  # Lower is better\n",
    "print(f'R-squared Score: {r2}')  # Higher is better here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117dfd6",
   "metadata": {},
   "source": [
    "### xGBoost - Gradient Boosting\n",
    "\n",
    "Many numeric variables were included in this xGBoost model. These include hours studied, attendance, sleep hours, previous scores, tutoring sessions, and physical activity. The data was first split into train and test, the model was created with the train data, and then the model was analyzed with the test data. The results were not favorable. The **R-squared value** was quite low at **0.12**, meaning only **11.8%** of the variance in exam scores is explained by the model, leaving a significant **88.2%** unexplained. Additionally, the **mean absolute error (MAE)** was **2.73**, which is noticeably higher than the random forest model. On a scale from 0 to 100, an average error of **2.73** is less accurate, and this model performed worse overall compared to the random forest model. There's significant room for improvement in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "479435a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 14.531362795653902\n",
      "Mean Absolute Error: 2.7283759613591303\n",
      "R-squared Score: 0.11758611040394995\n"
     ]
    }
   ],
   "source": [
    "X = dataset1[['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity', \n",
    "              'Teacher_Quality', 'Family_Income', 'Parental_Involvement']]\n",
    "Y = dataset1['Exam_Score'] \n",
    "\n",
    "categorical_columns = ['Teacher_Quality', 'Family_Income', 'Parental_Involvement']\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', ['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', \n",
    "                                'Tutoring_Sessions', 'Physical_Activity']),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(n_estimators=45, learning_rate=0.07, random_state=23))\n",
    "])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared Score: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa678a",
   "metadata": {},
   "source": [
    "### Random Forest Regression\n",
    "\n",
    "The math, reading, and writing exam scores were included in this random forest model. The data was first split into train and test, the model was created with the train data, and then the model was analyzed with the test data. It produced horrible results. The R-squared value was negative, indicating a performance worse than baseline. None of the variance can be explained by the model. Additionally, the mean absolute error was about 9.76. On a scale from 0 to 100, an average error of 9.76 indicates almost a 10% error rate. This data does not appear to be useful in predicting the results of a placement exam. Based on the EDA of this dataset, the results make sense because none of the variables were related. Their correlations were extremely low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60a689c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 141.6895601661111\n",
      "Mean Absolute Error: 9.787733333333332\n",
      "R-squared Score: -0.21580613084403177\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = dataset2[['Math_Score', 'Reading_Score', 'Writing_Score']]\n",
    "Y = dataset2['Placement_Score']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=28)\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=15)\n",
    "reg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f'R-squared Score: {r2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a8df7-8a0d-4bcf-87ab-686bbec35e08",
   "metadata": {},
   "source": [
    "## Results from the Dataset\n",
    "\n",
    "It appears that random forest regression and xGBoost models can be helpful in predicting exam scores from the provided information about students, but these models have much room for improvement. The R-squared value for the random forest regression was **0.54**, while for the xGBoost model it was significantly lower at **0.12**. However, the relatively low mean absolute error values, **1.32** for random forest and **2.73** for xGBoost, demonstrate some potential for use with future student data, though accuracy improvements are necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
